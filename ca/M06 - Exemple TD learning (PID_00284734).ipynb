{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.883 · Aprenentatge per reforç</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Màster universitari de Ciència de Dades</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudis d'Informàtica, Multimèdia i Telecomunicació</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Mòdul 6: exemples d'algorismes de _TD learning_\n",
    "\n",
    "En aquest _notebook_ carregarem alguns exemples dels algorismes de _TD learning_ vistos en el mòdul didàctic associat. \n",
    "\n",
    "En la primera part veurem el mètode de predicció TD(0) i després ens centrarem en SARSA i <i>Q-learning<i>. En tots els exemples emprarem l'entorn __GridWorld__ (en català, 'quadrícula') com a referència per facilitar la comparació entre mètodes i poder-nos centrar així en el desenvolupament dels algorismes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entorn __GridWorld__\n",
    "\n",
    "L'entorn __GridWorld__ consisteix en un agent que es mou en una quadrícula 3 × 4. En cada pas, l'agent té quatre opcions d'acció o moviment: a dalt, a baix, a la dreta i a l'esquerra. El joc acaba quan l'agent es troba en una cel·la que no permet més moviments. Tenim dos entorns: __*standard_grid*__ i __*negative_grid*__. \n",
    "\n",
    "En l'entorn *standard_grid*, l'agent rep una recompensa igual a 1 quan passa per la cel·la (0,3). Per contra, quan l'agent passa per la cel·la (1,3) rep una recompensa igual a –1. \n",
    "\n",
    "L'entorn *negative_grid* és semblat a l'*standard_grid*, però en aquest entorn es penalitza l'agent per cada moviment que fa. És a dir, rep una recompensa negativa per cada moviment. Aquest últim entorn s'usarà per a la implementació de SARSA i <i>Q-learning</i>. \n",
    "\n",
    "El codi per implementar aquest entorn, que està disponible en el fitxer adjunt `gridworldgame.py`, ha estat adaptat de l'enllaç següent:\n",
    "https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TD(0)\n",
    "\n",
    "En aquest apartat executarem el mètode TD(0) per a l'entorn __GridWorld__ en la seva versió `standard_grid`.\n",
    "\n",
    "\n",
    "En primer lloc, carregarem l'entorn __GridWorld__ i inicialitzarem els paràmetres de l'algorisme necessaris per determinar-ne la fórmula d'actualització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid, print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('O', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Inicialització\n",
    "En aquest apartat farem totes les operacions necessàries per executar l'algorisme. En primer lloc, definim un valor d'èpsilon ($\\epsilon$) per a les accions aleatòries. Aquesta part del codi ens serveix per assegurar que es visitin tots els estats durant l'execució dels passos de l'algorisme (és a dir, l'exploració)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "    # epsilon-soft per assegurar que es visitin tots els estats\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return an  else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació, posicionarem el nostre agent en el seu estat inicial. Definirem també els estats, les recompenses (en anglès, _rewards_) i les accions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(grid, policy):\n",
    "    # retorna una llista d'estats i els rewards corresponents\n",
    "    # inicia en l'estat designat\n",
    "    s = (2, 0)\n",
    "    grid.set_state(s)\n",
    "    states_and_rewards = [(s, 0)] # llista de les parelles (estat, reward)\n",
    "    while not grid.game_over():\n",
    "        a = policy[s]\n",
    "        a = random_action(a)\n",
    "        r = grid.move(a)\n",
    "        s = grid.current_state()\n",
    "        states_and_rewards.append((s,r))\n",
    "    \n",
    "    return states_and_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poder verificar l'entorn, podem visualitzar en la pantalla l'estructura de la nostra quadrícula (de mida 4 × 4) i els valors de recompensa associats a cada posició."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00|-1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n"
     ]
    }
   ],
   "source": [
    "grid = standard_grid()\n",
    "\n",
    "# print rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació, definirem la política inicial i la imprimirem per visualitzar-la en la quadrícula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  O  |     |  R  |     |\n",
      "---------------------------\n",
      "  O  |  R  |  R  |  O  |\n"
     ]
    }
   ],
   "source": [
    "# state -> action\n",
    "policy = {\n",
    "  (2, 0): 'O',\n",
    "  (1, 0): 'O',\n",
    "  (0, 0): 'R',\n",
    "  (0, 1): 'R',\n",
    "  (0, 2): 'R',\n",
    "  (1, 2): 'R',\n",
    "  (2, 1): 'R',\n",
    "  (2, 2): 'R',\n",
    "  (2, 3): 'O',\n",
    "}\n",
    "\n",
    "# política inicial\n",
    "print(\"initial policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidament, inicialitzarem els valors de $V(s)$ i els imprimirem en pantalla per poder comprovar-ne i verificar-ne el funcionament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n"
     ]
    }
   ],
   "source": [
    "V = {}\n",
    "states = grid.all_states()\n",
    "for s in states:\n",
    "    V[s] = 0\n",
    "\n",
    "# inicialitzar el valor per a tots els estats en la quadrícula\n",
    "print_values(V, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementació de l'algorisme TD(0)\n",
    "\n",
    "En aquest apartat implementarem l'algorisme TD(0), que s'executarà de manera iterativa fins a la seva convergència."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(1000):\n",
    "    # genera un episodi usant pi\n",
    "    states_and_rewards = play_game(grid, policy)\n",
    "    \n",
    "    # la primera parella (s,r) és l'estat inicial, que posem a 0\n",
    "    # atès que no tenim un reward per començar de manera simple.\n",
    "    # l'última parella (s,r) és l'estat terminal i el reward final.\n",
    "    # el valor de l'estat terminal és 0 per definició, així que no ens interessa actualitzar-lo.\n",
    "    for t in range(len(states_and_rewards) - 1):\n",
    "        s, _ = states_and_rewards[t]\n",
    "        s2, r = states_and_rewards[t+1]\n",
    "        # actualitzarem V(s) a la fi de cada episodi\n",
    "        V[s] = V[s] + ALPHA*(r + GAMMA*V[s2] - V[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, imprimirem els valors finals i la política final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.74| 0.84| 0.97| 0.00|\n",
      "---------------------------\n",
      " 0.67| 0.00|-0.95| 0.00|\n",
      "---------------------------\n",
      " 0.61|-0.52|-0.76|-0.96|\n",
      "\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  O  |     |  R  |     |\n",
      "---------------------------\n",
      "  O  |  R  |  R  |  O  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "\n",
    "print(\"\\nfinal policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SARSA\n",
    "\n",
    "En aquest apartat, implementarem el mètode SARSA per resoldre l'entorn __GridWorld__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Inicialització\n",
    "\n",
    "Carregarem l'entorn __GridWorld__ i inicialitzarem els paràmetres de l'algorisme que apareixen en la seva fórmula d'actualització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid, print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('O', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidament, necessitarem definir l'`argmax(key)` i el `max(value)`, que són variables que ens serveixen per a la implementació de l'algorisme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # retorna l'argmax(key) i el max(value) d'un diccionari\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    \n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que en l'exemple anterior, continuem amb la inicialització de les accions aleatòries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "    # epsilon-soft per assegurar que es visitin tots els estats\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a  \n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquesta cas, utilitzarem l'entorn __*negative_grid*__, que implementa una penalització (recompensa negativa) per cada moviment. D'aquesta forma, s'indica a l'agent que ha de trobar el camí més curt per resoldre el problema (és a dir, la política òptima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "# imprimir rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Implementació de l'algorisme SARSA\n",
    "\n",
    "A continuació, implementarem l'algorisme. És interessant notar que no inicialitzarem la política, sinó els valors de $Q$ més recents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (1, 2): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (0, 0): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 3): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 0): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (1, 3): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (1, 0): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 2): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (0, 3): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (0, 2): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 1): {'D': 0, 'R': 0, 'O': 0, 'L': 0}}\n"
     ]
    }
   ],
   "source": [
    "# inicialitzar Q(s,a)\n",
    "Q = {}\n",
    "states = grid.all_states()\n",
    "for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        Q[s][a] = 0\n",
    "\n",
    "# valors inicials de Q per a tots els estat en la quadrícula\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara crearem les variables `update_counts` i `update_counts_sa`, que ens serviran per saber quantes vegades actualitzarem els valors de $Q(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_counts = {}\n",
    "update_counts_sa = {}\n",
    "\n",
    "for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        update_counts_sa[s][a] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el següent codi implementarem els passos de l'algorisme SARSA, que s'executarà de manera iterativa fins a la seva convergència."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 2000\n",
      "iteration: 4000\n",
      "iteration: 6000\n",
      "iteration: 8000\n"
     ]
    }
   ],
   "source": [
    "# repetir fins a la convergència\n",
    "t = 1.0\n",
    "deltes = []\n",
    "\n",
    "for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "        t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "        print(\"iteration:\", it)\n",
    "\n",
    "    # en lloc de generar un episodi, jugarem un episodi i l'enviarem en loop, com aquí a sota\n",
    "\n",
    "    s = (2, 0) # start state\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # la primera (s,r) és l'estat inicial i val 0\n",
    "    # (atès que no tenim un reward) per començar el joc de manera fàcil.\n",
    "    # l'última (s,r) és l'estat terminal i el reward final.\n",
    "    # el valor per l'estat terminal és 0 per definició, així que no ens importa fer una actualització.\n",
    "\n",
    "    a = max_dict(Q[s])[0]\n",
    "    a = random_action(a, eps=0.5/t)\n",
    "    biggest_change = 0\n",
    "    \n",
    "    while not grid.game_over():\n",
    "        r = grid.move(a)\n",
    "        s2 = grid.current_state()\n",
    "\n",
    "        # necessitem l'acció successiva, atès que Q(s,a) depèn de Q(s',a')\n",
    "        # si s2 no està en la política, és l'estat terminal; tots els Q són 0\n",
    "        a2 = max_dict(Q[s2])[0]\n",
    "        a2 = random_action(a2, eps=0.5/t) # epsilon-greedy\n",
    "\n",
    "        # actualitzarem Q(s,a) quan provem l'episodi\n",
    "        alpha = ALPHA / update_counts_sa[s][a]\n",
    "        update_counts_sa[s][a] += 0.005\n",
    "        old_qsa = Q[s][a]\n",
    "        Q[s][a] = Q[s][a] + alpha*(r + GAMMA*Q[s2][a2] - Q[s][a])\n",
    "        biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "        # volem saber quantes vegades actualitzem Q(s)\n",
    "        update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "        # el pròxim estat serà el nou estat\n",
    "        s = s2\n",
    "        a = a2\n",
    "\n",
    "    deltes.append(biggest_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidament, imprimirem els valors de delta ($\\delta$) per visualitzar la convergència de l'algorisme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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 seu+jG5Ma6zprjDEmKauGMsYYk5QlC2OMMUlZsjDGGJOUJQtjjDFJWbIwxhiTlCULY4wxSVmyMMYYk5QlC2OMMUn9f2wfI9EOYlz7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltes)\n",
    "plt.xlabel('Iteracions')\n",
    "plt.ylabel('Delta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el codi següent, procedirem a determinar la política òptima a partir dels $Q$.\n",
    "\n",
    "Per fer aquest procés, haurem de trobar els valors $V$ a partir dels valors de $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-df84bdb07325>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-df84bdb07325>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    policy[s] = an  V[s] = max_q\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "policy = {}\n",
    "V = {}\n",
    "\n",
    "for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a\n",
    "    V[s] = max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzarem els $V$ per pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.18| 0.18| 0.18| 0.00|\n",
      "---------------------------\n",
      " 0.18| 0.00| 0.04| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.02| 0.03| 0.00|\n"
     ]
    }
   ],
   "source": [
    "print(\"update counts:\")\n",
    "total = np.sum(list(update_counts.values()))\n",
    "\n",
    "for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "\n",
    "print_values(update_counts, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per finalitzar, imprimirem els valors de $V(s)$ finals i la política trobada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.50| 0.72| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.30| 0.00| 0.73| 0.00|\n",
      "---------------------------\n",
      " 0.13| 0.21| 0.44| 0.20|\n",
      "\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  O  |     |  O  |     |\n",
      "---------------------------\n",
      "  O  |  R  |  O  |  L  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "\n",
    "print(\"\\nfinal policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. _Q-Learning_\n",
    "\n",
    "En aquest apartat, implementarem el mètode _Q-learning_ per resoldre l'entorn __GridWorld__ (en el cas de *negative_grid*) i compararem els resultats obtinguts amb el mètode que hem implementat en l'apartat anterior (el mètode SARSA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Inicialització\n",
    "\n",
    "Carregarem l'entorn __GridWorld__ i inicialitzarem els paràmetres de l'algorisme i de les seves regles d'actualització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gridWorldGame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c21c30acd04b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgridWorldGame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstandard_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSMALL_ENOUGH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gridWorldGame'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid,print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('O', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com en el cas anterior de l'algorisme SARSA, definim l'`argmax(key)` i el `max(value)`, que són variables que ens serveixen per a la implementació de l'algorisme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # retorna l'argmax(key) i el max(value) d'un diccionari\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    \n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialitzem les accions aleatòries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "    # epsilon-soft per assegurar que es visiten tots els estats\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a  \n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que en l'exemple anterior, utilitzarem l'entorn __*negative_grid*__, que implementa una penalització per cada moviment. D'aquesta forma, l'agent buscarà el camí més curt per resoldre el problema (és a dir, la política òptima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "# imprimir rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Implementació de l'algorisme _Q-Learning_\n",
    "\n",
    "Ara implementarem l'algorisme. Com en el cas anterior de la implementació de l'algorisme SARSA, tampoc inicialitzarem la política, sinó que inicialitzarem emprant els valors de $Q$ més recents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (1, 2): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (0, 0): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 3): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 0): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (1, 3): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (1, 0): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 2): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (0, 3): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (0, 2): {'D': 0, 'R': 0, 'O': 0, 'L': 0}, (2, 1): {'D': 0, 'R': 0, 'O': 0, 'L': 0}}\n"
     ]
    }
   ],
   "source": [
    "# inicialitzar Q(s,a)\n",
    "Q = {}\n",
    "states = grid.all_states()\n",
    "\n",
    "for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        Q[s][a] = 0\n",
    "\n",
    "# valors inicials de Q values per a tots els estats de la quadrícula\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creem les variables `update-counts` i `update_counts_sa`, que ens serviran per saber quantes vegades actualitzarem els valors de $Q(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_counts = {}\n",
    "update_counts_sa = {}\n",
    "\n",
    "for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        update_counts_sa[s][a] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot veure, fins a aquest punt no es poden observar diferències respecte a l'algorisme SARSA presentat en la secció anterior.\n",
    "\n",
    "A continuació, implementarem els passos de l'algorisme _Q-learning_ fins a la seva convergència. És important notar les diferències, aquí sí, respecte a l'exemple mostrat en la secció anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 2000\n",
      "iteration: 4000\n",
      "iteration: 6000\n",
      "iteration: 8000\n"
     ]
    }
   ],
   "source": [
    "# repetir fins a la convergència\n",
    "t = 1.0\n",
    "deltes = []\n",
    "\n",
    "for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "        t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "        print(\"iteration:\", it)\n",
    "\n",
    "    # en lloc de generar un episodi, jugarem un episodi i l'enviarem en loop, com aquí a sota\n",
    "\n",
    "    s = (2, 0) # estat inicial\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # la primera (s,r) és l'estat inicial i val 0 \n",
    "    # (atès que no tenim un reward) per començar el joc de manera fàcil.\n",
    "    # l'última (s,r) és l'estat terminal i el reward final.\n",
    "    # el valor per l'estat terminal és 0 per definició, així que no ens importa fer una actualització.\n",
    "\n",
    "    a, _ = max_dict(Q[s])\n",
    "    biggest_change = 0\n",
    "    while not grid.game_over():\n",
    "        a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
    "        # una acció random també funciona, però seria mes lenta atès que podríem topar contra els murs\n",
    "        # a = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "        r = grid.move(a)\n",
    "        s2 = grid.current_state()\n",
    "\n",
    "        # adaptive learning rate\n",
    "        alpha = ALPHA / update_counts_sa[s][a]\n",
    "        update_counts_sa[s][a] += 0.005\n",
    "\n",
    "        # actualitzarem Q(s,a) cada vegada que provem un episodi\n",
    "        old_qsa = Q[s][a]\n",
    "        # la diferència entre SARSA i Q-Learning és que Q-Learning\n",
    "        # usa max[a']{ Q(s',a')} en l'actualització\n",
    "        # encara que no acabarem fent aquella acció en el pas següent\n",
    "        a2, max_q_s2a2 = max_dict(Q[s2])\n",
    "        Q[s][a] = Q[s][a] + alpha*(r + GAMMA*max_q_s2a2 - Q[s][a])\n",
    "        biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "        # volem saber quantes vegades actualitzem Q(s)\n",
    "        update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "        # el pròxim estat serà el nou estat\n",
    "        s = s2\n",
    "        a = a2\n",
    "   \n",
    "    deltes.append(biggest_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimirem els valors de delta ($\\delta$) per visualitzar la convergència de l'algorisme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltes)\n",
    "plt.xlabel('Iteracions')\n",
    "plt.ylabel('Delta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara podem determinar la política òptima a partir de $Q$. Per fer aquest pas, haurem de trobar $V$ a partir de $Q$. \n",
    "\n",
    "Aquests passos són, de nou, semblants als utilitzats en la implementació de l'algorisme SARSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determinar la política a partir de Q*\n",
    "# trobar V* des de Q*\n",
    "policy = {}\n",
    "V = {}\n",
    "\n",
    "for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a  \n",
    "    V[s] = max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem els valors de $V$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.03| 0.04| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.02| 0.00| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.19| 0.18| 0.02|\n"
     ]
    }
   ],
   "source": [
    "print(\"update counts:\")\n",
    "total = np.sum(list(update_counts.values()))\n",
    "\n",
    "for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "\n",
    "print_values(update_counts, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, podem imprimir els valors de $V(s)$ finals i la política trobada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.46|\n",
      "\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  O  |     |  O  |     |\n",
      "---------------------------\n",
      "  R  |  R  |  O  |  L  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "\n",
    "print(\"\\nfinal policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
