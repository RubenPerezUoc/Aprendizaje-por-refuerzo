{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.883 · Aprendizaje por refuerzo</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario de Ciencia de Datos (<i>Data Science</i>)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Módulo 6: ejemplos de algoritmos de _TD learning_\n",
    "\n",
    "En este _notebook_ cargaremos algunos ejemplos de los algoritmos de _TD learning_ vistos en el módulo didáctico asociado. \n",
    "\n",
    "En la primera parte veremos el método de predicción TD(0) y después nos centraremos en SARSA y Q-learning. En todos los ejemplos emplearemos el entorno __GridWorld__ (en castellano, 'cuadrícula') como referencia, para facilitar la comparación entre métodos y así podernos centrar en el desarrollo de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entorno __GridWorld__\n",
    "\n",
    "El entorno __GridWorld__ consiste en un agente que se mueve en una cuadrícula 3 × 4. En cada paso, el agente tiene cuatro opciones de acción o movimiento: arriba, abajo, derecha e izquierda. El juego termina cuando el agente se encuentra en una celda que no permite más movimientos. Tenemos dos entornos __*standard_grid*__ y __*negative_grid*__. \n",
    "\n",
    "En el entorno *standard_grid*, el agente recibe una recompensa igual a 1 cuando pasa por la celda (0,3). Por el contrario, cuando el agente pasa por la celda (1,3) recibe una recompensa igual a –1. \n",
    "\n",
    "El entorno *negative_grid* es parecido al *standard_grid*, pero en este entorno se penaliza al agente por cada movimiento que hace. Es decir, recibe una recompensa negativa para cada movimiento. Este último entorno se usará para la implementación de SARSA y Q-learning. \n",
    "\n",
    "El código para implementar este entorno, que se encuentra disponible en el fichero adjunto `gridWorldGame.py`, ha sido adaptado del siguiente enlace:\n",
    "https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TD(0)\n",
    "\n",
    "En este apartado ejecutaremos el método TD(0) para el entorno __GridWorld__ en su versión `standard_grid`.\n",
    "\n",
    "\n",
    "En primer lugar, cargaremos el entorno __GridWorld__ e inicializaremos los parámetros del algoritmo necesarios para determinar su fórmula de actualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid, print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Inicialización\n",
    "En este apartado vamos a hacer todas aquellas operaciones necesarias para ejecutar el algoritmo. En primer lugar, definimos un valor de épsilon ($\\epsilon$) para las acciones aleatorias. Esta parte del código nos sirve para asegurar que se visiten todos los estados durante la ejecución de los pasos del algoritmo (es decir, la exploración)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "    # epsilon-soft para asegurar que se visiten todos los estados\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a\n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a posicionar nuestro agente en su estado inicial. Definiremos también los estados, las recompensas (en inglés, _rewards_) y las acciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(grid, policy):\n",
    "    # retorna una lista de estados y los rewards correspondientes\n",
    "    # inicia en el estado designado\n",
    "    s = (2, 0)\n",
    "    grid.set_state(s)\n",
    "    states_and_rewards = [(s, 0)] # lista de las parejas (estado, reward)\n",
    "    while not grid.game_over():\n",
    "        a = policy[s]\n",
    "        a = random_action(a)\n",
    "        r = grid.move(a)\n",
    "        s = grid.current_state()\n",
    "        states_and_rewards.append((s, r))\n",
    "    \n",
    "    return states_and_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder verificar el entorno, podemos visualizar en la pantalla la estructura de nuestra cuadrícula (de tamañao 4 × 4) y los valores de recompensa asociados a cada posición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00|-1.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n"
     ]
    }
   ],
   "source": [
    "grid = standard_grid()\n",
    "\n",
    "# print rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, definiremos la política inicial y la imprimiremos para visualizarla en la cuadrícula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  R  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  R  |  U  |\n"
     ]
    }
   ],
   "source": [
    "# state -> action\n",
    "policy = {\n",
    "  (2, 0): 'U',\n",
    "  (1, 0): 'U',\n",
    "  (0, 0): 'R',\n",
    "  (0, 1): 'R',\n",
    "  (0, 2): 'R',\n",
    "  (1, 2): 'R',\n",
    "  (2, 1): 'R',\n",
    "  (2, 2): 'R',\n",
    "  (2, 3): 'U',\n",
    "}\n",
    "\n",
    "# politica inicial\n",
    "print(\"initial policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente, procederemos a inicializar los valores de $V(s)$ e imprimirlos en pantalla para poder comprobar y verificar el funcionamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n",
      "---------------------------\n",
      " 0.00| 0.00| 0.00| 0.00|\n"
     ]
    }
   ],
   "source": [
    "V = {}\n",
    "states = grid.all_states()\n",
    "\n",
    "for s in states:\n",
    "    V[s] = 0\n",
    "\n",
    "# inicializar el valor para todos los estados en la cuadricula\n",
    "print_values(V, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementación del algoritmo TD(0)\n",
    "\n",
    "En este apartado vamos a implementar el algoritmo TD(0), que se ejecutará de forma iterativa hasta su convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(1000):\n",
    "    # genera un episodio usando pi\n",
    "    states_and_rewards = play_game(grid, policy)\n",
    "    \n",
    "    # la primera pareja (s, r) es el estado inicial,y lo ponemos a 0\n",
    "    # dado que no tenemos un reward, para empezar de forma simple.\n",
    "    # la última pareja (s, r) es el estado terminal y el reward final.\n",
    "    # el valor del estado terminal es 0 por definición, así que no nos interesa actualizarlo.\n",
    "    for t in range(len(states_and_rewards) - 1):\n",
    "        s, _ = states_and_rewards[t]\n",
    "        s2, r = states_and_rewards[t+1]\n",
    "        # actualizaremos V(s) al fin de cada episodio\n",
    "        V[s] = V[s] + ALPHA*(r + GAMMA*V[s2] - V[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, imprimiremos los valores finales y la política final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.74| 0.84| 0.97| 0.00|\n",
      "---------------------------\n",
      " 0.67| 0.00|-0.95| 0.00|\n",
      "---------------------------\n",
      " 0.61|-0.52|-0.76|-0.96|\n",
      "\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  R  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  R  |  U  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "\n",
    "print(\"\\nfinal policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SARSA\n",
    "\n",
    "En este apartado, implementaremos el método SARSA para resolver el entorno GridWorld. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Inicialización\n",
    "\n",
    "Cargaremos el entorno __GridWorld__ e inicializaremos los parámetros del algoritmo que aparecen en su fórmula de actualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid, print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente, necesitaremos definir el `argmax(key)` y el `max(value)`, que son variables que nos sirven para la implementación del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # retorna el argmax (key) y max (value) de un diccionario\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    \n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el ejemplo anterior, continuamos con la inicialización de las acciones aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "    # epsilon-soft para asegurar que se visiten todos los estados\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a\n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta caso, vamos a utilizar el entorno __*negative_grid*__ que implementa una penalización (recompensa negativa) por cada movimiento. De esta forma, se indica al agente que debe encontrar el camino más corto para resolver el problema (es decir, la política óptima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "# emprimir rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Implementación del algoritmo SARSA\n",
    "\n",
    "A continuación, procederemos a la implementación del algoritmo. Es interesante notar que no vamos a inicializar la política, sino que inicializaremos los valores de $Q$ más recientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (1, 2): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (0, 0): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 3): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 0): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (1, 3): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (1, 0): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 2): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (0, 3): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (0, 2): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 1): {'D': 0, 'R': 0, 'U': 0, 'L': 0}}\n"
     ]
    }
   ],
   "source": [
    "# initializar Q(s,a)\n",
    "Q = {}\n",
    "states = grid.all_states()\n",
    "\n",
    "for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        Q[s][a] = 0\n",
    "\n",
    "# valores iniciales de Q para todos los estado en la cuadicula\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos ahora las variables `update_counts` y `update_counts_sa`, que nos serviran para saber cuantas veces actualizaremos los valores de $Q(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_counts = {}\n",
    "update_counts_sa = {}\n",
    "\n",
    "for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        update_counts_sa[s][a] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementaremos, en el siguiente código, los pasos del algoritmo SARSA, que se ejecutará de forma iterativa hasta su convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 2000\n",
      "iteration: 4000\n",
      "iteration: 6000\n",
      "iteration: 8000\n"
     ]
    }
   ],
   "source": [
    "# repetir hasta la convergencia\n",
    "t = 1.0\n",
    "deltas = []\n",
    "\n",
    "for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "        t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "        print(\"iteration:\", it)\n",
    "\n",
    "    # en lugar de generar un episodio, jugaremos un episodio y lo mandaremos en loop, como aquí abajo\n",
    "\n",
    "    s = (2, 0) # start state\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # la primera (s,r) es el estado inicial y vale 0\n",
    "    # (dado que no tenemos un reward), para empezar el juego de manera facil.\n",
    "    # la ultima (s, r) es el estado terminal y el reward final.\n",
    "    # el valor por el estado terminal es por definición 0, así que no nos importa hacer una actualización.\n",
    "\n",
    "    a = max_dict(Q[s])[0]\n",
    "    a = random_action(a, eps=0.5/t)\n",
    "    biggest_change = 0\n",
    "    while not grid.game_over():\n",
    "        r = grid.move(a)\n",
    "        s2 = grid.current_state()\n",
    "\n",
    "        # necesitamos la acción sucesiva, dado que Q(s,a) depende de Q(s',a')\n",
    "        # si s2 no está en la politica, entonces es el estado terminal; todos los Q son 0\n",
    "        a2 = max_dict(Q[s2])[0]\n",
    "        a2 = random_action(a2, eps=0.5/t) # epsilon-greedy\n",
    "\n",
    "        # actualizaremos Q(s,a) cuando probamos el episodio\n",
    "        alpha = ALPHA / update_counts_sa[s][a]\n",
    "        update_counts_sa[s][a] += 0.005\n",
    "        old_qsa = Q[s][a]\n",
    "        Q[s][a] = Q[s][a] + alpha*(r + GAMMA*Q[s2][a2] - Q[s][a])\n",
    "        biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "        # queremos saber cuantas veces actualizamos Q(s)\n",
    "        update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "        # el próximo estado será el nuevo estado\n",
    "        s = s2\n",
    "        a = a2\n",
    "\n",
    "    deltas.append(biggest_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente, imprimiremos los valores de delta ($\\delta$) para visualizar la convergencia del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Delta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente código, procederemos a determinar la política óptima a partir de los $Q^*$.\n",
    "\n",
    "Para realizar este proceso, deberemos hallar los valores $V^*$ a partir de los valores de $Q^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {}\n",
    "V = {}\n",
    "\n",
    "for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a\n",
    "    V[s] = max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizaremos por pantalla los $V^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.18| 0.18| 0.18| 0.00|\n",
      "---------------------------\n",
      " 0.18| 0.00| 0.04| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.02| 0.03| 0.00|\n"
     ]
    }
   ],
   "source": [
    "print(\"update counts:\")\n",
    "total = np.sum(list(update_counts.values()))\n",
    "\n",
    "for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "\n",
    "print_values(update_counts, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, procederemos a imprimir los valores de $V(s)$ finales y la política encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.50| 0.72| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.30| 0.00| 0.73| 0.00|\n",
      "---------------------------\n",
      " 0.13| 0.21| 0.44| 0.20|\n",
      "\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "\n",
    "print(\"\\nfinal policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. _Q-Learning_\n",
    "\n",
    "En este apartado, implementaremos el método _Q-learning_ para resolver el entorno __GridWorld__ (en el caso de *negative_grid*) y compararemos los resultados obtenidos con el método que hemos implementado en el apartado anterior (el método SARSA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Inicialización\n",
    "\n",
    "Cargaremos el entorno __GridWorld__ e inicializamos los parámetros del algoritmo y de sus reglas de actualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gridWorldGame import standard_grid, negative_grid,print_values, print_policy\n",
    "\n",
    "SMALL_ENOUGH = 1e-3\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en el caso anterior del algoritmo SARSA, definimos el `argmax(key)` y el `max(value)`, que son variables que nos sirven para la implementación del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # retorna el argmax (key) y max (value) de un diccionario\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    \n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos las acciones aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action(a, eps=0.1):\n",
    "    # epsilon-soft para asegurar que se visiten todos los estados\n",
    "    p = np.random.random()\n",
    "    if p < (1 - eps):\n",
    "        return a\n",
    "    else:\n",
    "        return np.random.choice(ALL_POSSIBLE_ACTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el ejemplo anterior, vamos a utilizar el entorno __*negative_grid*__ que implementa una penalización por cada movimiento. De esta forma, el agente buscará el camino más corto para resolver el problema (es decir, la política óptima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n"
     ]
    }
   ],
   "source": [
    "grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "# emprimir rewards\n",
    "print(\"rewards:\")\n",
    "print_values(grid.rewards, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Implementación del algoritmo _Q-Learning_\n",
    "\n",
    "Pasaremos ahora a la implementación del algoritmo. Como en el caso anterior de la implementación del algoritmo SARSA, en este caso tampoco vamos a inicializar la política, sino que inicializamos empleando los valores de $Q$ más recientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (1, 2): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (0, 0): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 3): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 0): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (1, 3): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (1, 0): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 2): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (0, 3): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (0, 2): {'D': 0, 'R': 0, 'U': 0, 'L': 0}, (2, 1): {'D': 0, 'R': 0, 'U': 0, 'L': 0}}\n"
     ]
    }
   ],
   "source": [
    "# initializar Q(s,a)\n",
    "Q = {}\n",
    "states = grid.all_states()\n",
    "\n",
    "for s in states:\n",
    "    Q[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        Q[s][a] = 0\n",
    "\n",
    "# valores iniciales de Q values para todos los estados de la cuadricula\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las variables `update-counts` y `update_counts_sa` que nos serviran para saber cuantas veces actualizaremos los valores de $Q(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_counts = {}\n",
    "update_counts_sa = {}\n",
    "\n",
    "for s in states:\n",
    "    update_counts_sa[s] = {}\n",
    "    for a in ALL_POSSIBLE_ACTIONS:\n",
    "        update_counts_sa[s][a] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede notarse, hasta este punto no pueden observarse diferencias respecto al algoritmo SARSA presentado en la sección anterior.\n",
    "\n",
    "A continuación, implementaremos los pasos del algoritmo _Q-learning_ hasta su convergencia. Es importante notar las diferencias, aquí sí, con el ejemplo mostrado en la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 2000\n",
      "iteration: 4000\n",
      "iteration: 6000\n",
      "iteration: 8000\n"
     ]
    }
   ],
   "source": [
    "# repetir hasta la convergencia\n",
    "t = 1.0\n",
    "deltas = []\n",
    "\n",
    "for it in range(10000):\n",
    "    if it % 100 == 0:\n",
    "        t += 1e-2\n",
    "    if it % 2000 == 0:\n",
    "        print(\"iteration:\", it)\n",
    "\n",
    "    # en lugar de generar un episodio, jugaremos un episodio y lo manderemos en loop, como aquí abajo\n",
    "\n",
    "    s = (2, 0) # estado inicial\n",
    "    grid.set_state(s)\n",
    "\n",
    "    # la primera (s,r) es el estado inicial y vale 0 \n",
    "    # (dado que no tenemos un reward), para empezar el juego de manera facil.\n",
    "    # la ultima (s, r) es el estado terminal y el reward final.\n",
    "    # el valor por el estado terminal es por definición 0, así que no nos importa hacer una actualización.\n",
    "\n",
    "    a, _ = max_dict(Q[s])\n",
    "    biggest_change = 0\n",
    "    while not grid.game_over():\n",
    "        a = random_action(a, eps=0.5/t) # epsilon-greedy\n",
    "        # una accion random también funciona, pero sería mas lento dado que puedes chocar contra los muros\n",
    "        # a = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "        r = grid.move(a)\n",
    "        s2 = grid.current_state()\n",
    "\n",
    "        # adaptive learning rate\n",
    "        alpha = ALPHA / update_counts_sa[s][a]\n",
    "        update_counts_sa[s][a] += 0.005\n",
    "\n",
    "        # actualizaremos Q(s,a) cada vez que probamos un episodio\n",
    "        old_qsa = Q[s][a]\n",
    "        # la diferencia entre SARSA y Q-Learning es que Q-Learning\n",
    "        # usa max[a']{ Q(s',a')} en la actualización\n",
    "        # aunque no terminaremos tomando aquella acción en el paso siguiente\n",
    "        a2, max_q_s2a2 = max_dict(Q[s2])\n",
    "        Q[s][a] = Q[s][a] + alpha*(r + GAMMA*max_q_s2a2 - Q[s][a])\n",
    "        biggest_change = max(biggest_change, np.abs(old_qsa - Q[s][a]))\n",
    "\n",
    "        # queremos saber cuantas veces actualizamos Q(s)\n",
    "        update_counts[s] = update_counts.get(s,0) + 1\n",
    "\n",
    "        # el próximo estado será el nuevo estado\n",
    "        s = s2\n",
    "        a = a2\n",
    "    \n",
    "    deltas.append(biggest_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimiremos los valores de delta ($\\delta$) para visualizar la convergencia del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Delta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos determinar la política óptima a partir de $Q^*$. Para realizar este paso, deberemos encontrar $V^*$ a partir de $Q^*$. \n",
    "\n",
    "Estos pasos son, de nuevo, parecidos a los utilizados en la implementación del algoritmo SARSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determinar la politica a partir de Q*\n",
    "# encontra V* desde Q*\n",
    "policy = {}\n",
    "V = {}\n",
    "\n",
    "for s in grid.actions.keys():\n",
    "    a, max_q = max_dict(Q[s])\n",
    "    policy[s] = a\n",
    "    V[s] = max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los valores de $V^*$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update counts:\n",
      "---------------------------\n",
      " 0.03| 0.04| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.02| 0.00| 0.17| 0.00|\n",
      "---------------------------\n",
      " 0.19| 0.19| 0.18| 0.02|\n"
     ]
    }
   ],
   "source": [
    "print(\"update counts:\")\n",
    "total = np.sum(list(update_counts.values()))\n",
    "\n",
    "for k, v in update_counts.items():\n",
    "    update_counts[k] = float(v) / total\n",
    "\n",
    "print_values(update_counts, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos imprimir los valores de $V(s)$ finales y la política encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.62| 0.80| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.46| 0.00| 0.80| 0.00|\n",
      "---------------------------\n",
      " 0.31| 0.46| 0.62| 0.46|\n",
      "\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  R  |  R  |  U  |  L  |\n"
     ]
    }
   ],
   "source": [
    "print(\"final values:\")\n",
    "print_values(V, grid)\n",
    "\n",
    "print(\"\\nfinal policy:\")\n",
    "print_policy(policy, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
